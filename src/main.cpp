/***********************************************************************************
* Данная программа рассчитывает значения матрицы пискслей и записывает их в формате 
* P3, т.е. цвета даны в ASCII - 24 бита на пиксель (по 8 бит на r,g,b). 
* 
* Алгоритм вычисления цвета конкретного пикселя основан на методе трассировки лучей.
* Суть которого: в каждый пиксель области просмотра испускается луч из камеры, 
* который можно описать вектором b. Положение пикселя (точка P), в который попадет 
* луч, будет описан как вектора a + b, где а вектор к виртуальной камере.
* Если задать некотрый параметр t для вектора направления b, то будет возможно 
* сдвигать точку P вдоль направления луча. Таким образом, если при некоторых 
* значениях t, точка P(t) = a + tb будет лежать на некоторой поверхности, то пере-
* сеченный пиксель области просмотра будет покрашен в соответствующий цвет.
* 
* При камере заданной в произвольной точке, необходимо компенсировать расстояние 
* от точка начала координат до точки A для точки задающей направление луча. Пусть
* имеется некоторая точка D (пиксель области просмотра) и есть неоторый вектор d
* к этой точке. Если P(t) = а + td, тогда получившийся луч будет параллелен точке 
* D. Т.к. требуется именно пересечение точки D, выше вводится вектор b = (d - a).
* 
* Выходной файл ((>) file.ppm) содержит значения для пикселя в количестве 256 x 256, 
* значения которых не превышают 255.
*
* Файл .ppm является простым форматом хранения цветного изображения. Также может 
* быть использован в качестве промежуточного формата при конвертации растровых 
* изображений. 
* 
* Внутренне представление, по соглашени. r,g,b компонентов должно находиться в 
* диапазоне [0,1]. Для этого единичный вектор (нормализованный), который имеют 
* компоненты в диапазоне [-1,1], адаптируются: 0.5 * (unit_direction.y() + 1.0) 
* (линейное масштабирование).
* 
* Т.е. для каждого компонента конкретного пикселя определяется степень 
* интенсивности конкретного компонента цвета (r,g,b). 
*
* cmake ..
* cmake --build . --config Release
***********************************************************************************/

#include <iostream>
#include "ray.h"
#include "vec3.h"
#include "color.h"

/* hit_sphere() решает уравнение x^2 + y^2 + z^2 = r^2 как квадратное уравнение с
 * использование формулы нахождения дискриминанта. Уравнение x^2 + y^2 + z^2 = r^2
 * представимо в виде (C - P(t))(C - P(t)) = r^2, где P(t) некоторая точка, заданная
 * уравнением a + tb. Записав уравнение в виде (C - a - tb)(C - a - tb) = r^2 и взяв
 * С - а как временную переменную OC, уравнене можно решить как квадратное уравне-
 * ние, раскрыв скобки и записав уравнение как t^2b^2 + 2tbOC - OC^2 - r^2 = 0, где
 * a = t^2b^2, b = 2tbOC, c = OC^2 - r^2. Решив это уравнение через формулу дискре-
 * минта, можно найти такие точки t, при который будет найдена точка P(t) на по-
 * верхности сферы.
 * 
 * Math: пусть есть некоторая точка P(t) на поверхности сферы, тогда можно сказать 
 * что a + tb = c + rp, где с - вектор к центру сферы, а rp - вектор от центра сферы
 * к точке P(t). 

 * a + tb = c + rp -> P(t) - c = rp -> c - P(t) = - rp. При возведениее правой и 
 * левой части уравнения в квадрат получается (c - P(t))(c - P(t)) = (-rp^2) = r^2,
 * что является уравнением выше.
*/
double hit_sphere(const point3& sp_center, double radius, const ray& r)
{
	vec3 oc = sp_center - r.origin(); 
	//double a = dot(r.direction(), r.direction());
	//double b = -2.0*dot(r.direction(), oc);
	//double c = dot(oc,oc) - radius*radius;
	
	//double discriminant = b*b - 4*a*c;
	
	double a = r.direction().length_squared();
	double h = dot(r.direction(), oc);
	double c = oc.length_squared() - radius*radius;
	double discriminant = h*h - a*c;

	/*
     * Во-первых, скалярное произведение вектора на себя равно квадрату длины этого
	 * вектора, что позволяет упростить вычисление a.
	 * Во-вторых, если b = -2d*oc, тогда можно представить точку h = b/-2 = d*oc, 
	 * что позволяет изабивьться от двух операций: -2.0*dot() дли b и 2.0*a как 
	 * конечная операция перед возвратом значения:
	 * 
	 * (-b +- sqrt(b^2-4ac))/2a
	 * (-(-2h) +- sqrt((-2h)^2 - 4ac))/2a = (2h +- sqrt(h^2 - ac))/2a =
	 * =(h +- sqrt(h^2 - ac))/a
	*/
	
	
	if (discriminant < 0) { return -1.0;}
	else { 
		//return (-b - std::sqrt(discriminant)) / (2.0*a); 
		return (h - std::sqrt(discriminant)) / a;
	}
}

/* 
 * Функция ray_color() возвращает цвет пикселя в зависимости от того, пересекает
 * ли луч какой-либо объект.

 * Если луч, выпущенный через пиксель из области просмотра не пересекает поверхности
 * объекта, то цвет пикселя рассчитывается как участок неба: в этом случае 
 * ray_color() линейно смешивает белый и синий цвета в зависимости от высоты направ-
 * ления луча после нормализации, т.е. масштабирования до единичного вектора и пре-
 * образования к диапазону [0,1] (прибавив 1 к единичному вектору и умножив его на 
 * 0.5 - (линейное масштабирование)).
 * 
 * Если луч пересекает некоторый объект при некотором t, то будет найдена точка 
 * P(t), то теперь можно найти нормаль n к этой точке (в описании функции hit_spehre
 * это вектор rp). Нормаль n = P(t) - c = a + tb - c. 
 * 
 * Цвет объекта рассчитывается в зависимости от положения точки N.
*/
color ray_color(const ray& r) {
	/* sphere */
	double t = hit_sphere(point3(0,0,-1), 0.5, r);
	if (t > 0.0) {
		//vec3 N = unitv(r.at(t) - point3(0,0,-1));
		vec3 N = (r.at(t) - point3(0,0,-1))/0.5; // некоторе упрощения для объекта сферы, т.к. известно что длина нормали равна радиусу сферы
		return 0.5*color(N.x() + 1, N.y() + 1, N.z() + 1); // 0.5*color(N.i() + 1) -- линейное масштабирование до диапазона значений [0,1]
														   
	}

	/* sky */
	vec3 unit_direction = unitv(r.direction());
	double a = 0.5 * (unit_direction.y() + 1.0); // [-1;1] -> [0;1], 0.0 <= a <= 1.0
	/* linear interpolation */
	return (1.0-a)*color(1.0,1.0,1.0) + a*color(0.5, 0.7, 1.0); // a = 1.0 -> синий, a = 0.0 -> белый
}

int main() 
{
	/* image settings */
	double ASPECT_RATIO = 16.0 / 9.0;
	int IMAGE_WIDTH = 400;
	int IMAGE_HEIGHT = int(IMAGE_WIDTH / ASPECT_RATIO);
	IMAGE_HEIGHT = (IMAGE_HEIGHT < 1) ? 1 : IMAGE_HEIGHT; // Высота изображения не должна быть < 1.

	/* viewport settings */
	double VIEWPORT_HEIGHT = 2.0; // высота просмотра выбрана произвольно
	double VIEWPORT_WIDTH = VIEWPORT_HEIGHT * (double(IMAGE_WIDTH)/IMAGE_HEIGHT);
	vec3 VIEWPORT_U = vec3(VIEWPORT_WIDTH, 0, 0);
	vec3 VIEWPORT_V = vec3(0, -VIEWPORT_HEIGHT, 0);

	/* camera settings */
	double FOCAL_LENGTH = 1.0; 
	point3 CAMERA_CENTER(0,0,0);

	/* calculate delta vectotrs */
	vec3 PIXEL_DELTA_U = VIEWPORT_U / IMAGE_WIDTH;
	vec3 PIXEL_DELTA_V = VIEWPORT_V / IMAGE_HEIGHT;

	/* calculate location viewport upper left/pixel(0,0) */
	point3 VIEWPORT_UPPER_LEFT = CAMERA_CENTER - vec3(0, 0, FOCAL_LENGTH) - VIEWPORT_U/2 - VIEWPORT_V/2;
	point3 PIXEL_LOC_00 = VIEWPORT_UPPER_LEFT + 0.5 * (PIXEL_DELTA_U + PIXEL_DELTA_V);

	std::ios_base::sync_with_stdio(0);
	/* render */
	std::cout << "P3\n" << IMAGE_WIDTH << ' ' << IMAGE_HEIGHT << "\n255\n";
	for (int j = 0; j < IMAGE_HEIGHT; ++j) {
		std::clog << "\rScanlines remaining: " << (IMAGE_HEIGHT - j) << ' ' << std::flush;
		for (int i = 0; i < IMAGE_WIDTH; ++i) {
			point3 pixel_center = PIXEL_LOC_00 + (i * PIXEL_DELTA_U) + (j * PIXEL_DELTA_V); // определяем пиксь в области просмотра 
			point3 ray_direction = pixel_center - CAMERA_CENTER; // компенсируем расстояние от точки начала координа до камеры, 
																 // для корректного перечечения пикселя области просмотра. 
			ray r(CAMERA_CENTER,ray_direction); // испускаем луч

			color pix_color = ray_color(r); // определяем цвет пересеченного пикслея области просмотра
			write_color(std::cout, pix_color); // записываем в выхондной поток > .ppm.
		}
	}
	std::clog << "\rDone.                 \n";
}