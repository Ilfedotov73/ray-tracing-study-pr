/***********************************************************************************
* Данная программа рассчитывает значения матрицы пискслей и записывает их в формате 
* P3, т.е. цвета даны в ASCII - 24 бита на пиксель (по 8 бит на r,g,b). 
* 
* Алгоритм вычисления цвета конкретного пикселя основан на методе трассировки лучей.
* Суть которого: в каждый пиксель области просмотра испускается луч из камеры, 
* который можно описать вектором b. Положение пикселя (точка P), в который попадет 
* луч, будет описан как вектора a + b, где а вектор к виртуальной камере.
* Если задать некотрый параметр t для вектора направления b, то будет возможно 
* сдвигать точку P вдоль направления луча. Таким образом, если при некоторых 
* значениях t, точка P(t) = a + tb будет лежать на некоторой поверхности, то пере-
* сеченный пиксель области просмотра будет покрашен в соответствующий цвет.
* 
* При камере заданной в произвольной точке, необходимо компенсировать расстояние 
* от точка начала координат до точки A для точки задающей направление луча. Пусть
* имеется некоторая точка D (пиксель области просмотра) и есть неоторый вектор d
* к этой точке. Если P(t) = а + td, тогда получившийся луч будет параллелен точке 
* D. Т.к. требуется именно пересечение точки D, выше вводится вектор b = (d - a).
* 
* Выходной файл ((>) file.ppm) содержит значения для пикселя в количестве 256 x 256, 
* значения которых не превышают 255.
*
* Файл .ppm является простым форматом хранения цветного изображения. Также может 
* быть использован в качестве промежуточного формата при конвертации растровых 
* изображений. 
* 
* Внутренне представление, по соглашени. r,g,b компонентов должно находиться в 
* диапазоне [0,1]. Для этого единичный вектор (нормализованный), который имеют 
* компоненты в диапазоне [-1,1], адаптируются: 0.5 * (unit_direction.y() + 1.0) 
* (линейное масштабирование).
* 
* Т.е. для каждого компонента конкретного пикселя определяется степень 
* интенсивности конкретного компонента цвета (r,g,b). 
*
* cmake ..
* cmake --build . --config Release
***********************************************************************************/

#include "rt_settings.h"
#include "hittable.h"
#include "hittable_list.h"
#include "sphere.h"

/* 
 * Функция ray_color() принимает луч и константную ссылку на объект реализующий 
 * абстрактный класс hittable - hittable_list, который содержит массив указателей
 * на поверхности (также реализующие hittable). 
 * 
 * В теле функции создается объект класса hit_record rec, который регистрирует 
 * информацию о пересечении объекта лучом. Если луч пересекает один из поверхностей
 * world.hit() вернет true и ray_color вернет цвет пикселя "затененного" нормалью.
 * 
 * Затенение нормалями: цвет пикселя поверхности определяется положением нормали 
 * единичной длины, что позволяет получить значение пикселся в диапазоне [-1,1] для
 * последуюущего линейного масштабирование в диапазон [0,1].
 * 
 * Если пересечение с объектами не происходит,то рассчитывается градиент от белого
 * к синему, в зависимости о высоты пикселя. Чем ближе значение a к единице, тем 
 * ближе значение к синему (0.5, 0.7, 1.0) - рассчет неба для сцены.
*/
color ray_color(const ray& r, const hittable& world) {
	hit_record rec;
	if (world.hit(r, 0, INF, rec)) {
		return 0.5 * (rec.normal + color(1,1,1)); // 0.5*(normal + 1) -- линейное масштабирование до диапазона значений [0,1]
	}

	/* sky */
	vec3 unit_direction = unitv(r.direction());
	double a = 0.5 * (unit_direction.y() + 1.0); // [-1;1] -> [0;1], 0.0 <= a <= 1.0
	/* linear interpolation */
	return (1.0-a)*color(1.0,1.0,1.0) + a*color(0.5, 0.7, 1.0); // a = 1.0 -> синий, a = 0.0 -> белый
}

int main() 
{
	/* image settings */
	double ASPECT_RATIO = 16.0 / 9.0;
	int IMAGE_WIDTH = 400;
	int IMAGE_HEIGHT = int(IMAGE_WIDTH / ASPECT_RATIO);
	IMAGE_HEIGHT = (IMAGE_HEIGHT < 1) ? 1 : IMAGE_HEIGHT; // Высота изображения не должна быть < 1.

	/* viewport settings */
	double VIEWPORT_HEIGHT = 2.0; // высота просмотра выбрана произвольно
	double VIEWPORT_WIDTH = VIEWPORT_HEIGHT * (double(IMAGE_WIDTH)/IMAGE_HEIGHT);
	vec3 VIEWPORT_U = vec3(VIEWPORT_WIDTH, 0, 0);
	vec3 VIEWPORT_V = vec3(0, -VIEWPORT_HEIGHT, 0);

	/* camera settings */
	double FOCAL_LENGTH = 1.0; 
	point3 CAMERA_CENTER(0,0,0);

	/* calculate delta vectotrs */
	vec3 PIXEL_DELTA_U = VIEWPORT_U / IMAGE_WIDTH;
	vec3 PIXEL_DELTA_V = VIEWPORT_V / IMAGE_HEIGHT;

	/* calculate location viewport upper left/pixel(0,0) */
	point3 VIEWPORT_UPPER_LEFT = CAMERA_CENTER - vec3(0, 0, FOCAL_LENGTH) - VIEWPORT_U/2 - VIEWPORT_V/2;
	point3 PIXEL_LOC_00 = VIEWPORT_UPPER_LEFT + 0.5 * (PIXEL_DELTA_U + PIXEL_DELTA_V);

	/* world */
	hittable_list WORLD;
	WORLD.add(make_shared<sphere>(point3(0,0,-1), 0.5));
	WORLD.add(make_shared<sphere>(point3(0,-100.5,-1), 100));

	std::ios_base::sync_with_stdio(0);
	/* render */
	std::cout << "P3\n" << IMAGE_WIDTH << ' ' << IMAGE_HEIGHT << "\n255\n";
	for (int j = 0; j < IMAGE_HEIGHT; ++j) {
		std::clog << "\rScanlines remaining: " << (IMAGE_HEIGHT - j) << ' ' << std::flush;
		for (int i = 0; i < IMAGE_WIDTH; ++i) {
			point3 pixel_center = PIXEL_LOC_00 + (i * PIXEL_DELTA_U) + (j * PIXEL_DELTA_V); // определяем пиксь в области просмотра 
			point3 ray_direction = pixel_center - CAMERA_CENTER; // компенсируем расстояние от точки начала координа до камеры, 
																 // для корректного перечечения пикселя области просмотра. 
			ray r(CAMERA_CENTER,ray_direction); // испускаем луч

			color pix_color = ray_color(r, WORLD); // определяем цвет пересеченного пикслея области просмотра
			write_color(std::cout, pix_color); // записываем в выхондной поток > .ppm.
		}
	}
	std::clog << "\rDone.                 \n";
}